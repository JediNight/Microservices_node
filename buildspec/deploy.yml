version: 0.2
phases:
  install:
      - echo "Install Phase - Nothing to do using latest Amazon Linux Docker Image for CodeBuild which has all AWS Tools - https://github.com/aws/aws-codebuild-docker-images/blob/master/al2/x86_64/standard/3.0/Dockerfile"
  pre_build:
    commands:
      - echo Entered the pre_build phase...
      - echo Logging in to Amazon EKS...
      - aws eks --region us-east-1 update-kubeconfig --name harbr-eks-demo-QPWM0dm9 
      - docker login --username $DOCKERHUB_USERNAME --password $DOCKERHUB_PASSWORD
      # get commit hash
  build:
    commands:
      - CREDENTIALS=$(aws sts assume-role --role-arn $EKS_KUBECTL_ROLE_ARN --role-session-name codebuild-kubectl --duration-seconds 900)
      - export AWS_ACCESS_KEY_ID="$(echo ${CREDENTIALS} | jq -r '.Credentials.AccessKeyId')"
      - export AWS_SECRET_ACCESS_KEY="$(echo ${CREDENTIALS} | jq -r '.Credentials.SecretAccessKey')"
      - export AWS_SESSION_TOKEN="$(echo ${CREDENTIALS} | jq -r '.Credentials.SessionToken')"
      - export AWS_EXPIRATION=$(echo ${CREDENTIALS} | jq -r '.Credentials.Expiration')
      # Setup kubectl with our EKS Cluster and create namespace
      - aws eks update-kubeconfig --name $EKS_CLUSTER_NAME
      - kubectl create ns $EKS_NAMESPACE || true
      # set current namespace
      - kubectl config set-context $(kubectl config current-context) --namespace=$EKS_NAMESPACE 
      # apply kube specs
      - kubectl apply -f infra/k8s/
      - echo "Completed applying changes to Kubernetes Objects"
      # Create Artifacts which we can use if we want to continue our pipeline for other stages
artifacts:
  files:
    - build.json
    - kube-manifests/*

